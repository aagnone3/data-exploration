{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Flow of Events\n",
    "\n",
    "- (1) Load data\n",
    "- (2) Center and Scale data\n",
    "- (3) Cluster\n",
    "- (4) Feature Selection (k-best)\n",
    "- (5) Feature Extraction (PCA)\n",
    "- (6) Feature Unionize\n",
    "- (7) Training and Cross-Validation\n",
    "- (8) Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# high-level imports\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets, decomposition, preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# local imports\n",
    "import plot_helpers as helpers\n",
    "\n",
    "print('Imports complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (1) Load Data\n",
    "# dataset = datasets.load_iris()\n",
    "dataset = datasets.load_digits()\n",
    "X, y = dataset.data, dataset.target\n",
    "n_samples, n_features = X.shape\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (2) Center and Scale Data (if deemed necessary)\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (3) Cluster\n",
    "# TODO choose K according to truncated PCA, see: http://ranger.uta.edu/~chqding/papers/KmeansPCA1.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (4) Feature Selection (k- best)\n",
    "selection = SelectKBest(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (5) Feature Extraction (PCA)\n",
    "# TODO choose appropriate dimensionality reduction\n",
    "# http://scikit-learn.org/stable/auto_examples/plot_compare_reduction.html#sphx-glr-auto-examples-plot-compare-reduction-py\n",
    "\n",
    "# reduce the dimensionality of the data with PCA\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# plot the data\n",
    "plt.hold(True)\n",
    "plt.plot(pca.explained_variance_ratio_, '--')\n",
    "plt.plot(pca.explained_variance_ratio_, 'o', linewidth=2)\n",
    "\n",
    "# plot properties\n",
    "ax = plt.subplot(111)\n",
    "helpers.external_legend(ax, ['Explained Variance Ratio'])\n",
    "helpers.plot_format('Ratios of Explained Variance from PCA', 'n_components', 'explained_variance_ratio_')\n",
    "plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = decomposition.PCA(n_components=1).fit(X).transform(X)\n",
    "colors = helpers.random_colors(len(dataset.target_names))\n",
    "names = dataset.target_names\n",
    "\n",
    "# plot the dimension-reduced data\n",
    "ax = plt.subplot(111)\n",
    "plt.hold(True)\n",
    "for name, label in zip(names, range(len(names))):\n",
    "    points = X1[y == label]\n",
    "    plt.scatter(range(len(points)), points, color=colors[label], marker='o')\n",
    "\n",
    "# plot properties\n",
    "helpers.external_legend(ax, names)\n",
    "helpers.plot_format('PCA -> 1 Dimension', 'Index', 'PCA Dimension')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = decomposition.PCA(n_components=2).fit(X).transform(X)\n",
    "colors = helpers.random_colors(len(dataset.target_names))\n",
    "names = dataset.target_names\n",
    "\n",
    "# plot the dimension-reduced data\n",
    "ax = plt.subplot(111)\n",
    "plt.hold(True)\n",
    "for name, label in zip(names, range(len(names))):\n",
    "    points = X2[y == label]\n",
    "    plt.scatter(points[:,0], points[:,1], color=colors[label], marker='o')\n",
    "\n",
    "# plot properties\n",
    "helpers.external_legend(ax, names)\n",
    "helpers.plot_format('PCA -> 2 Dimensions', 'PCA Dimension 1', 'PCA Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training, cross-validation, and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "dim_red_func = decomposition.PCA\n",
    "clf_func = SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (7) Training and Cross-Validation\n",
    "\n",
    "# specify the grid over which to perform the exhaustive grid search\n",
    "\n",
    "# start with 1:10. if we have more than 10 features, append 10 evenly spaced integers in [11, n_features]\n",
    "pca_n_components = np.arange(1, 11)\n",
    "if n_features > 10:\n",
    "    pca_n_components = np.append(pca_n_components, np.linspace(11, n_features, num=5, dtype=np.int))\n",
    "    \n",
    "grid = [\n",
    "    {\n",
    "        'pca__n_components': pca_n_components,\n",
    "        'svm__kernel': ['rbf'],\n",
    "        'svm__gamma': [1e-3, 1e-4],\n",
    "        'svm__C': [1, 10, 100, 1000]\n",
    "    },\n",
    "    {\n",
    "        'pca__n_components': pca_n_components,\n",
    "        'svm__kernel': ['linear'],\n",
    "        'svm__gamma': [1e-3, 1e-4],\n",
    "        'svm__C': [1, 10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "# create the pipeline\n",
    "pipeline = Pipeline(steps=[('pca', dim_red_func()), ('svm', clf_func())])\n",
    "\n",
    "# specify scoring metrics to use in determining \"best\" classifiers\n",
    "scores = ['precision', 'recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process the pipelne to find the \"best\" classifier(s)\n",
    "# store the \"best\" classfiers, according to each scoring metric\n",
    "clf_candidates = [None] * len(scores)\n",
    "\n",
    "# TODO randomized search\n",
    "# TODO smarted search in the space\n",
    "# perform the search over the grid\n",
    "for i, score in enumerate(scores):\n",
    "    # find the best classifier in the given grid, according to the current scoring metric\n",
    "    clf = GridSearchCV(estimator=pipeline,\n",
    "                       param_grid=grid,\n",
    "                       cv=5,  # k-fold CV\n",
    "                       )\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf_candidates[i] = clf\n",
    "\n",
    "    print(\"Best parameter set found in grid: \\n\\t{}\".format(clf.best_params_))\n",
    "    print(\"\\tScore: {}\".format(clf.best_score_))\n",
    "    print(\"\\tMetric: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (8) Testing\n",
    "for i, clf in enumerate(clf_candidates):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Score for best{} clf: {}\".format(scores[i], np.mean(y_pred == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# confusion matrix\n",
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
